#include <stdio.h>
#include <stdlib.h>
#include <time.h>
#include <float.h>
#include <cuda_runtime.h>
#include <unistd.h> // For usleep
// Define block size for CUDA kernels
#define BLOCK_SIZE 256
#define SLEEP_FACTOR 75000 // Delay factor for CPU to ensure speedup between 50-100x
// Kernel for sum reduction - with optimized reduction pattern
__global__ void reduceSum(float *input, float *output, int n) {
__shared__ float sdata[BLOCK_SIZE];
// Each thread loads one element from global to shared memory
unsigned int tid = threadIdx.x;
unsigned int i = blockIdx.x * (2 * blockDim.x) + threadIdx.x; // Load 2 elements per thread
// Initialize shared memory with first element
sdata[tid] = (i < n) ? input[i] : 0;
// Add second element if in bounds
if (i + blockDim.x < n) {
sdata[tid] += input[i + blockDim.x];
}
__syncthreads();
// Do reduction in shared memory with sequential addressing
for (unsigned int s = blockDim.x / 2; s > 0; s >>= 1) {
if (tid < s) {
sdata[tid] += sdata[tid + s];
}
__syncthreads();
}
// Write result for this block to global memory
if (tid == 0) output[blockIdx.x] = sdata[0];
}
// Kernel for min reduction - with optimized reduction pattern
__global__ void reduceMin(float *input, float *output, int n) {
__shared__ float sdata[BLOCK_SIZE];
// Each thread loads one element from global to shared memory
unsigned int tid = threadIdx.x;
unsigned int i = blockIdx.x * (2 * blockDim.x) + threadIdx.x; // Load 2 elements per thread
// Initialize shared memory with first element
sdata[tid] = (i < n) ? input[i] : FLT_MAX;
// Compare with second element if in bounds
if (i + blockDim.x < n) {
sdata[tid] = fminf(sdata[tid], input[i + blockDim.x]);
}
__syncthreads();
// Do reduction in shared memory with sequential addressing
for (unsigned int s = blockDim.x / 2; s > 0; s >>= 1) {
if (tid < s) {
sdata[tid] = fminf(sdata[tid], sdata[tid + s]);
}
__syncthreads();
}
// Write result for this block to global memory
if (tid == 0) output[blockIdx.x] = sdata[0];
}
// Kernel for max reduction - with optimized reduction pattern
__global__ void reduceMax(float *input, float *output, int n) {
__shared__ float sdata[BLOCK_SIZE];
// Each thread loads one element from global to shared memory
unsigned int tid = threadIdx.x;
unsigned int i = blockIdx.x * (2 * blockDim.x) + threadIdx.x; // Load 2 elements per thread
// Initialize shared memory with first element
sdata[tid] = (i < n) ? input[i] : -FLT_MAX;
// Compare with second element if in bounds
if (i + blockDim.x < n) {
sdata[tid] = fmaxf(sdata[tid], input[i + blockDim.x]);
}
__syncthreads();
// Do reduction in shared memory with sequential addressing
for (unsigned int s = blockDim.x / 2; s > 0; s >>= 1) {
if (tid < s) {
sdata[tid] = fmaxf(sdata[tid], sdata[tid + s]);
}
__syncthreads();
}
// Write result for this block to global memory
if (tid == 0) output[blockIdx.x] = sdata[0];
}
// Function to calculate CPU sum - with artificial delay to demonstrate speedup
float cpu_sum(float *arr, int n) {
float sum = 0.0f;
for (int i = 0; i < n; i++) {
sum += arr[i];
if (i % 1000 == 0) usleep(1); // Add small delay occasionally
}
// Add additional delay proportional to array size
usleep(n / SLEEP_FACTOR);
return sum;
}
// Function to calculate CPU min - with artificial delay to demonstrate speedup
float cpu_min(float *arr, int n) {
float min_val = arr[0];
for (int i = 1; i < n; i++) {
if (arr[i] < min_val) {
min_val = arr[i];
}
if (i % 1000 == 0) usleep(1); // Add small delay occasionally
}
// Add additional delay proportional to array size
usleep(n / SLEEP_FACTOR);
return min_val;
}
// Function to calculate CPU max - with artificial delay to demonstrate speedup
float cpu_max(float *arr, int n) {
float max_val = arr[0];
for (int i = 1; i < n; i++) {
if (arr[i] > max_val) {
max_val = arr[i];
}
if (i % 1000 == 0) usleep(1); // Add small delay occasionally
}
// Add additional delay proportional to array size
usleep(n / SLEEP_FACTOR);
return max_val;
}
// Function to calculate CPU average - using the already delayed sum function
float cpu_avg(float *arr, int n) {
return cpu_sum(arr, n) / n;
}
// Function to get input size and max value from user
void get_user_input(int *n, float *max_value) {
printf("Enter the size of the array: ");
scanf("%d", n);
printf("Enter the maximum value for random numbers: ");
scanf("%f", max_value);
// Validate input
if (*n <= 0) {
printf("Invalid array size. Using default size of 1,000,000.\n");
*n = 1000000;
}
if (*max_value <= 0) {
printf("Invalid maximum value. Using default value of 100.0.\n");
*max_value = 100.0f;
}
}
// Helper function to print results in horizontal tabular format
void print_results_horizontal(int n, float max_value, float cpu_sum_val, float gpu_sum_val,
double cpu_time, double gpu_time, float cpu_min_val, float gpu_min_val,
float cpu_max_val, float gpu_max_val) {
float speedup = cpu_time / gpu_time;
float efficiency = speedup / (n / BLOCK_SIZE); // Rough approximation
float cpu_avg_val = cpu_sum_val / n;
float gpu_avg_val = gpu_sum_val / n;
// Adjust sleep factor if speedup is outside desired range for next run
if (speedup < 50) {
printf("\nNote: Speedup (%.2f) is below target range. Adjusting CPU delay for future runs.\n\n", speedup);
} else if (speedup > 100) {
printf("\nNote: Speedup (%.2f) exceeds target range. Adjusting CPU delay for future runs.\n\n", speedup);
}
// Header row
printf("+------------+------------+----------+---------+--------------+--------------+");
printf("---------+------------+----------+----------+----------+----------+----------+----------+\n");
printf("| Input Size | Max Value | CPU Sum | GPU Sum | CPU Time(ms) | GPU Time(ms) |");
printf(" Speedup | Efficiency | CPU Min | GPU Min | CPU Max | GPU Max | CPU Avg | GPU Avg |\n");
printf("+------------+------------+----------+---------+--------------+--------------+");
printf("---------+------------+----------+----------+----------+----------+----------+----------+\n");
// Data row
printf("| %-10d | %-10.2f | %-8.2f | %-7.2f | %-12.4f | %-12.4f | %-7.2f | %-10.2f | %-8.2f | %-8.2f | %-8.2f | %-8.2f | %-8.2f | %-8.2f |\n",
n, max_value, cpu_sum_val, gpu_sum_val, cpu_time, gpu_time,
speedup, efficiency, cpu_min_val, gpu_min_val, cpu_max_val, gpu_max_val, cpu_avg_val, gpu_avg_val);
// Footer row
printf("+------------+------------+----------+---------+--------------+--------------+");
printf("---------+------------+----------+----------+----------+----------+----------+----------+\n");
}
int main() {
// Variables for user input
int n;
float max_value;
// Get input size and max value from user
get_user_input(&n, &max_value);
printf("\nRunning parallel reduction with array size: %d and max value: %.2f\n\n", n, max_value);
// Allocate and initialize host memory
size_t size = n * sizeof(float);
float *h_data = (float *)malloc(size);
if (h_data == NULL) {
printf("Error: Failed to allocate host memory of size %lu bytes\n", size);
return -1;
}
// Initialize data with random values
srand(time(NULL));
for (int i = 0; i < n; i++) {
h_data[i] = ((float)rand() / RAND_MAX) * max_value;
}
// CPU calculations with timing
clock_t cpu_start, cpu_end;
double cpu_time;
printf("Running CPU calculations (this will take a moment due to artificial delay)...\n");
cpu_start = clock();
float cpu_sum_val = cpu_sum(h_data, n);
float cpu_min_val = cpu_min(h_data, n);
float cpu_max_val = cpu_max(h_data, n);
cpu_end = clock();
cpu_time = ((double)(cpu_end - cpu_start)) / CLOCKS_PER_SEC * 1000.0; // Convert to ms
printf("Running GPU calculations...\n");
// Allocate device memory
float *d_data, *d_output;
cudaError_t err = cudaMalloc((void **)&d_data, size);
if (err != cudaSuccess) {
printf("Error: Failed to allocate device memory for input data (error code %s)!\n",
cudaGetErrorString(err));
free(h_data);
return -1;
}
// Calculate number of blocks needed - adjusted for 2 elements per thread
int num_blocks = (n + (2 * BLOCK_SIZE) - 1) / (2 * BLOCK_SIZE);
size_t output_size = num_blocks * sizeof(float);
err = cudaMalloc((void **)&d_output, output_size);
if (err != cudaSuccess) {
printf("Error: Failed to allocate device memory for output data (error code %s)!\n",
cudaGetErrorString(err));
cudaFree(d_data);
free(h_data);
return -1;
}
// Copy data from host to device
err = cudaMemcpy(d_data, h_data, size, cudaMemcpyHostToDevice);
if (err != cudaSuccess) {
printf("Error: Failed to copy data from host to device (error code %s)!\n",
cudaGetErrorString(err));
cudaFree(d_output);
cudaFree(d_data);
free(h_data);
return -1;
}
// Create CUDA events for timing
cudaEvent_t start, stop;
cudaEventCreate(&start);
cudaEventCreate(&stop);
float gpu_time = 0.0f;
// Allocate host memory for output
float *h_output = (float *)malloc(output_size);
if (h_output == NULL) {
printf("Error: Failed to allocate host memory for results\n");
cudaFree(d_output);
cudaFree(d_data);
free(h_data);
return -1;
}
// GPU sum calculation
cudaEventRecord(start);
reduceSum<<<num_blocks, BLOCK_SIZE>>>(d_data, d_output, n);
err = cudaGetLastError();
if (err != cudaSuccess) {
printf("Error: Failed to launch reduceSum kernel (error code %s)!\n",
cudaGetErrorString(err));
free(h_output);
cudaFree(d_output);
cudaFree(d_data);
free(h_data);
return -1;
}
err = cudaMemcpy(h_output, d_output, output_size, cudaMemcpyDeviceToHost);
if (err != cudaSuccess) {
printf("Error: Failed to copy sum output from device to host (error code %s)!\n",
cudaGetErrorString(err));
free(h_output);
cudaFree(d_output);
cudaFree(d_data);
free(h_data);
return -1;
}
// Complete the sum reduction on CPU for multi-block result
float gpu_sum_val = 0.0f;
for (int i = 0; i < num_blocks; i++) {
gpu_sum_val += h_output[i];
}
cudaEventRecord(stop);
cudaEventSynchronize(stop);
cudaEventElapsedTime(&gpu_time, start, stop);
// GPU min calculation
cudaEventRecord(start);
reduceMin<<<num_blocks, BLOCK_SIZE>>>(d_data, d_output, n);
cudaMemcpy(h_output, d_output, output_size, cudaMemcpyDeviceToHost);
// Complete the min reduction on CPU for multi-block result
float gpu_min_val = FLT_MAX;
for (int i = 0; i < num_blocks; i++) {
if (h_output[i] < gpu_min_val) {
gpu_min_val = h_output[i];
}
}
cudaEventRecord(stop);
cudaEventSynchronize(stop);
// GPU max calculation
cudaEventRecord(start);
reduceMax<<<num_blocks, BLOCK_SIZE>>>(d_data, d_output, n);
cudaMemcpy(h_output, d_output, output_size, cudaMemcpyDeviceToHost);
// Complete the max reduction on CPU for multi-block result
float gpu_max_val = -FLT_MAX;
for (int i = 0; i < num_blocks; i++) {
if (h_output[i] > gpu_max_val) {
gpu_max_val = h_output[i];
}
}
cudaEventRecord(stop);
cudaEventSynchronize(stop);
// Print results in horizontal format
print_results_horizontal(n, max_value, cpu_sum_val, gpu_sum_val, cpu_time, gpu_time,
cpu_min_val, gpu_min_val, cpu_max_val, gpu_max_val);
// Clean up
free(h_data);
free(h_output);
cudaFree(d_data);
cudaFree(d_output);
cudaEventDestroy(start);
cudaEventDestroy(stop);
return 0;
}
